{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3553bfbf",
   "metadata": {},
   "source": [
    "## Homework 3: Machine Learning for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bab883c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>referral</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>north_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>referral</td>\n",
       "      <td>technology</td>\n",
       "      <td>3</td>\n",
       "      <td>65259.0</td>\n",
       "      <td>student</td>\n",
       "      <td>europe</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "      <td>45688.0</td>\n",
       "      <td>student</td>\n",
       "      <td>north_america</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>referral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>71016.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>north_america</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>organic_search</td>\n",
       "      <td>finance</td>\n",
       "      <td>3</td>\n",
       "      <td>92855.0</td>\n",
       "      <td>student</td>\n",
       "      <td>north_america</td>\n",
       "      <td>3</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1462 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lead_source       industry  number_of_courses_viewed  annual_income  \\\n",
       "0           paid_ads            NaN                         1        79450.0   \n",
       "1       social_media         retail                         1        46992.0   \n",
       "2             events     healthcare                         5        78796.0   \n",
       "3           paid_ads         retail                         2        83843.0   \n",
       "4           referral      education                         3        85012.0   \n",
       "...              ...            ...                       ...            ...   \n",
       "1457        referral  manufacturing                         1            NaN   \n",
       "1458        referral     technology                         3        65259.0   \n",
       "1459        paid_ads     technology                         1        45688.0   \n",
       "1460        referral            NaN                         5        71016.0   \n",
       "1461  organic_search        finance                         3        92855.0   \n",
       "\n",
       "     employment_status       location  interaction_count  lead_score  \\\n",
       "0           unemployed  south_america                  4        0.94   \n",
       "1             employed  south_america                  1        0.80   \n",
       "2           unemployed      australia                  3        0.69   \n",
       "3                  NaN      australia                  1        0.87   \n",
       "4        self_employed         europe                  3        0.62   \n",
       "...                ...            ...                ...         ...   \n",
       "1457     self_employed  north_america                  4        0.53   \n",
       "1458           student         europe                  2        0.24   \n",
       "1459           student  north_america                  3        0.02   \n",
       "1460     self_employed  north_america                  0        0.25   \n",
       "1461           student  north_america                  3        0.41   \n",
       "\n",
       "      converted  \n",
       "0             1  \n",
       "1             0  \n",
       "2             1  \n",
       "3             0  \n",
       "4             1  \n",
       "...         ...  \n",
       "1457          1  \n",
       "1458          1  \n",
       "1459          1  \n",
       "1460          1  \n",
       "1461          1  \n",
       "\n",
       "[1462 rows x 9 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Make everything lower case and change spaces to underscores (in both headings and data)\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "strings = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "for col in strings:\n",
    "    df[col] = df[col].str.lower().str.replace(' ', '_')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109dd58a",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9c6bcf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " lead_source                 128\n",
      "industry                    134\n",
      "number_of_courses_viewed      0\n",
      "annual_income               181\n",
      "employment_status           100\n",
      "location                     63\n",
      "interaction_count             0\n",
      "lead_score                    0\n",
      "converted                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if the missing values are presented in the features.\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# If there are missing values:\n",
    "# For categorical features, replace them with 'NA'\n",
    "df.fillna({'lead_source': 'NA', 'industry': 'NA', 'employment_status': 'NA', 'location': 'NA'}, inplace=True)\n",
    "# For numerical features, replace with with 0.0\n",
    "df.fillna({'annual_income': 0.0}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca8bb07",
   "metadata": {},
   "source": [
    "### Question 1. What is the most frequent observation (mode) for the column industry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5ed91c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent observation (mode) for the column industry is: retail\n"
     ]
    }
   ],
   "source": [
    "industry_mode = df['industry'].mode()[0]\n",
    "print(\"The most frequent observation (mode) for the column industry is:\", industry_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c77aa4",
   "metadata": {},
   "source": [
    "### Question 2.\n",
    "\n",
    "Create the correlation matrix for the numerical features of your dataset. In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "What are the two features that have the biggest correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8a28d18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>-0.023565</td>\n",
       "      <td>-0.004879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>0.009770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>0.015610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_count</th>\n",
       "      <td>-0.023565</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_score</th>\n",
       "      <td>-0.004879</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          number_of_courses_viewed  annual_income  \\\n",
       "number_of_courses_viewed                  1.000000       0.009770   \n",
       "annual_income                             0.009770       1.000000   \n",
       "interaction_count                        -0.023565       0.027036   \n",
       "lead_score                               -0.004879       0.015610   \n",
       "\n",
       "                          interaction_count  lead_score  \n",
       "number_of_courses_viewed          -0.023565   -0.004879  \n",
       "annual_income                      0.027036    0.015610  \n",
       "interaction_count                  1.000000    0.009888  \n",
       "lead_score                         0.009888    1.000000  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "df[numerical_features].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6524d73",
   "metadata": {},
   "source": [
    "What are the two features that have the biggest correlation?\n",
    "\n",
    "interaction_count and lead_score 0.009888\\\n",
    "number_of_courses_viewed and lead_score -0.004879\\\n",
    "number_of_courses_viewed and interaction_count -0.023565\\\n",
    "annual_income and interaction_count 0.027036"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96bd4ac",
   "metadata": {},
   "source": [
    "### Split the data.\n",
    "\n",
    "Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "Make sure that the target value y is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e5f99d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.converted.values\n",
    "y_val = df_val.converted.values\n",
    "y_test = df_test.converted.values\n",
    "\n",
    "del df_train['converted']\n",
    "del df_val['converted']\n",
    "del df_test['converted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b2b601",
   "metadata": {},
   "source": [
    "### Question 3.\n",
    "\n",
    "Calculate the mutual information score between y and other categorical variables in the dataset. Use the training set only. Round the scores to 2 decimals using round(score, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fa4146dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mutual information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lead_source</th>\n",
       "      <td>0.024803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_status</th>\n",
       "      <td>0.016345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <td>0.006161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>0.001453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mutual information\n",
       "lead_source                  0.024803\n",
       "employment_status            0.016345\n",
       "industry                     0.006161\n",
       "location                     0.001453"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "def calculate_mi(series):\n",
    "    return mutual_info_score(series, y_train)\n",
    "\n",
    "categorical_features = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "df_mi = df_train[categorical_features].apply(calculate_mi)\n",
    "df_mi = df_mi.sort_values(ascending=False).to_frame(name='mutual information')\n",
    "display(df_mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7becc67e",
   "metadata": {},
   "source": [
    "### Question 4. Now let's train a logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "01fd6d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model using all features is: 0.6996587030716723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = df_train[categorical_features + numerical_features].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val[categorical_features + numerical_features].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "# Fit the model on the training dataset.\n",
    "# To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "# model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "converted_decision = (y_pred >= 0.5)\n",
    "accuracy_all_features = (converted_decision == y_val).mean()\n",
    "#accuracy_all_features = round((converted_decision == y_val).mean(), 2)\n",
    "print(\"The accuracy of the model using all features is:\", accuracy_all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7960c",
   "metadata": {},
   "source": [
    "### Question 5.\n",
    "\n",
    "Let's find the least useful feature using the feature elimination technique.\\\n",
    "Train a model using the same features and parameters as in Q4 (without rounding).  <-- Done above\\\n",
    "Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\\\n",
    "For each feature, calculate the difference between the original accuracy and the accuracy without the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ce8ccffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in the accuracy of the model using all features except lead_source is: -0.0034129692832765013\n",
      "Difference in the accuracy of the model using all features except lead_source is: -0.0034129692832765013\n",
      "Difference in the accuracy of the model using all features except industry is: 0.0\n",
      "Difference in the accuracy of the model using all features except industry is: 0.0\n",
      "Difference in the accuracy of the model using all features except employment_status is: -0.0034129692832765013\n",
      "Difference in the accuracy of the model using all features except employment_status is: -0.0034129692832765013\n",
      "Difference in the accuracy of the model using all features except location is: 0.0\n",
      "Difference in the accuracy of the model using all features except location is: 0.0\n",
      "Difference in the accuracy of the model using all features except number_of_courses_viewed is: 0.11604095563139927\n",
      "Difference in the accuracy of the model using all features except number_of_courses_viewed is: 0.11604095563139927\n",
      "Difference in the accuracy of the model using all features except annual_income is: -0.14675767918088745\n",
      "Difference in the accuracy of the model using all features except annual_income is: -0.14675767918088745\n",
      "Difference in the accuracy of the model using all features except interaction_count is: 0.11262798634812288\n",
      "Difference in the accuracy of the model using all features except interaction_count is: 0.11262798634812288\n",
      "Difference in the accuracy of the model using all features except lead_score is: 0.0\n",
      "Difference in the accuracy of the model using all features except lead_score is: 0.0\n"
     ]
    }
   ],
   "source": [
    "all_features = categorical_features + numerical_features\n",
    "\n",
    "for current_feature in all_features:\n",
    "    remaining_features = all_features.copy()\n",
    "    remaining_features.remove(current_feature)\n",
    "\n",
    "    # Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    train_dict = df_train[remaining_features].to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "    val_dict = df_val[remaining_features].to_dict(orient='records')\n",
    "    X_val = dv.transform(val_dict)\n",
    "\n",
    "    # Fit the model on the training dataset.\n",
    "    # To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "    # model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "    y_pred = model.predict_proba(X_val)[:, 1]\n",
    "    converted_decision = (y_pred >= 0.5)\n",
    "    accuracy_remaining_features = (converted_decision == y_val).mean()\n",
    "    #accuracy_remaining_features = round((converted_decision == y_val).mean(), 2)\n",
    "    print(\"Difference in the accuracy of the model using all features except\", current_feature, \"is:\", accuracy_all_features - accuracy_remaining_features)\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "    y_pred = model.predict_proba(X_val)[:, 1]\n",
    "    converted_decision = (y_pred >= 0.5)\n",
    "    accuracy_remaining_features = (converted_decision == y_val).mean()\n",
    "    #accuracy_remaining_features = round((converted_decision == y_val).mean(), 2)\n",
    "    print(\"Difference in the accuracy of the model using all features except\", current_feature, \"is:\", accuracy_all_features - accuracy_remaining_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e89fa2",
   "metadata": {},
   "source": [
    "### Question 6.\n",
    "\n",
    "Now let's train a regularized logistic regression.\\\n",
    "Let's try the following values of the parameter C: [0.01, 0.1, 1, 10, 100].\\\n",
    "Train models using all the features as in Q4.\\\n",
    "Calculate the accuracy on the validation dataset and round it to 3 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb2532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using r-value: 0.01\n",
      "Using r-value: 0.1\n",
      "Using r-value: 1\n",
      "Using r-value: 10\n",
      "Using r-value: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "for r in [0.01, 0.1, 1, 10, 100]:\n",
    "    # Initialize the Ridge model with a specific alpha value\n",
    "    ridge_model = Ridge(alpha=r)\n",
    "\n",
    "    # Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    train_dict = df_train[categorical_features + numerical_features].to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "    val_dict = df_val[categorical_features + numerical_features].to_dict(orient='records')\n",
    "    X_val = dv.transform(val_dict)\n",
    "\n",
    "    # Fit the model on the training dataset.\n",
    "    # To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "    # model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "    y_pred = model.predict_proba(X_val)[:, 1]\n",
    "    converted_decision = (y_pred >= 0.5)\n",
    "    accuracy_all_features = (converted_decision == y_val).mean()\n",
    "    #accuracy_all_features = round((converted_decision == y_val).mean(), 2)\n",
    "    print(\"The accuracy of the model using all features is:\", accuracy_all_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
